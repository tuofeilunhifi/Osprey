nohup: ignoring input
[2024-01-30 15:37:55,400] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-30 15:37:57,731] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-01-30 15:37:57,732] [INFO] [runner.py:555:main] cmd = /opt/conda/envs/osprey/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None osprey/train/train_mem.py --deepspeed ./scripts/zero2.json --model_name_or_path /mnt/pfs-guan-ssai/cv/cjy/models/models--lmsys--vicuna-7b-v1.5/snapshots/de56c35b1763eaae20f4d60efd64af0a9091ebe5 --dataset_config ./osprey/configs/stage2.json --version v1 --vision_tower /mnt/pfs-guan-ssai/cv/cjy/models/models--laion--CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/snapshots/39918dfbdf69ccd2172e6510a430e92337ee23e1/open_clip_pytorch_model.bin --pretrain_mm_mlp_adapter /mnt/pfs-guan-ssai/cv/cjy/models/models--sunshine-lwt--osprey-v1.0-mlp2x-512px-convnext-pretrain-vicuna-7b-v1.5/snapshots/03564321e190dd4c101ba2c5a62fe8e9d76222f0/mm_projector.bin --mm_projector_type mlp2x_gelu --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --image_aspect_ratio pad --group_by_modality_length True --bf16 True --output_dir ./exp/stage2 --num_train_epochs 2 --per_device_train_batch_size 1 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 10000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to none --group_by_modality_length False
[2024-01-30 15:37:59,388] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-30 15:38:01,588] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-01-30 15:38:01,589] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-01-30 15:38:01,589] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-01-30 15:38:01,590] [INFO] [launch.py:163:main] dist_world_size=8
[2024-01-30 15:38:01,590] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-01-30 15:38:06,499] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-30 15:38:06,719] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-30 15:38:06,982] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-30 15:38:06,993] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-30 15:38:07,008] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-30 15:38:07,025] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-30 15:38:07,030] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-30 15:38:07,049] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-30 15:38:07,361] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-01-30 15:38:07,362] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-01-30 15:38:07,579] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-01-30 15:38:07,580] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-01-30 15:38:07,856] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-01-30 15:38:07,856] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-01-30 15:38:07,857] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-01-30 15:38:07,874] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-01-30 15:38:07,874] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-01-30 15:38:07,877] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-01-30 15:38:07,877] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-01-30 15:38:07,879] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-01-30 15:38:07,880] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-01-30 15:38:07,906] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-01-30 15:38:07,906] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-01-30 15:38:07,920] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-01-30 15:38:07,920] [INFO] [comm.py:594:init_distributed] cdb=None
You are using a model of type llama to instantiate a model of type osprey. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type osprey. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type osprey. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type osprey. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type osprey. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type osprey. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type osprey. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type osprey. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]